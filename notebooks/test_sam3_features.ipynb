{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f46d36",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "Clone repository and install dependencies (Colab only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec86d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell only on Google Colab\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    %cd /content\n",
    "    \n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/AntoFratta/DVARF.git\n",
    "    %cd /content/DVARF\n",
    "    \n",
    "    # Install dependencies (remove Windows-specific packages)\n",
    "    !grep -v \"triton-windows\" requirements.txt > requirements_colab.txt\n",
    "    !pip install -q -r requirements_colab.txt\n",
    "    \n",
    "    # Extract data\n",
    "    !apt-get update -y > /dev/null\n",
    "    !apt-get install -y unrar > /dev/null\n",
    "    !unrar x data.rar ./ > /dev/null\n",
    "    \n",
    "    print(\"✅ Colab setup complete!\")\n",
    "else:\n",
    "    # Local development: just add project root to path\n",
    "    from pathlib import Path\n",
    "    project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    print(f\"✅ Local setup complete! Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efcdf3b",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup SAM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path if not already added\n",
    "if IN_COLAB:\n",
    "    project_root = Path(\"/content/DVARF\")\n",
    "else:\n",
    "    project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from src.sam3_wrapper import Sam3ImageModel\n",
    "from src.prompts import CLASS_PROMPTS\n",
    "from src.config import get_images_dir\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"\\nClass prompts:\")\n",
    "for class_id, prompt in CLASS_PROMPTS.items():\n",
    "    print(f\"  Class {class_id}: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2d62b",
   "metadata": {},
   "source": [
    "## 3. Load SAM3 Model\n",
    "\n",
    "Initialize the SAM3 wrapper. This will download the model weights if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable debug mode to see internal SAM3 output structure\n",
    "os.environ[\"SAM3_DEBUG\"] = \"1\"\n",
    "\n",
    "print(\"Loading SAM3 model...\")\n",
    "model = Sam3ImageModel()\n",
    "print(\"✅ SAM3 model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b3b41",
   "metadata": {},
   "source": [
    "## 4. Test on Sample Images\n",
    "\n",
    "Run SAM3 on 2-3 images from the test split to verify feature extraction works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test images directory\n",
    "test_images_dir = project_root / \"data\" / \"raw\" / \"images\" / \"test\"\n",
    "\n",
    "# Select first 3 images for testing\n",
    "test_image_files = sorted(test_images_dir.glob(\"*.jpg\"))[:3]\n",
    "\n",
    "if not test_image_files:\n",
    "    print(\"❌ No test images found! Check that data was extracted correctly.\")\n",
    "else:\n",
    "    print(f\"Found {len(test_image_files)} test images:\")\n",
    "    for img_path in test_image_files:\n",
    "        print(f\"  - {img_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4bee1",
   "metadata": {},
   "source": [
    "### Test Single Image with Single Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first image with first class prompt\n",
    "if test_image_files:\n",
    "    test_img = test_image_files[0]\n",
    "    test_prompt = CLASS_PROMPTS[0]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing: {test_img.name}\")\n",
    "    print(f\"Prompt: '{test_prompt}'\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Run SAM3 prediction\n",
    "    prediction = model.predict_with_text(test_img, test_prompt)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREDICTION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check prediction outputs\n",
    "    print(f\"\\n✅ Boxes shape: {prediction.boxes.shape}\")\n",
    "    print(f\"✅ Scores shape: {prediction.scores.shape}\")\n",
    "    print(f\"✅ Masks shape: {prediction.masks.shape}\")\n",
    "    print(f\"✅ Features shape: {prediction.features.shape}\")\n",
    "    \n",
    "    num_detections = prediction.boxes.shape[0]\n",
    "    print(f\"\\nNumber of detections: {num_detections}\")\n",
    "    \n",
    "    if num_detections > 0:\n",
    "        print(f\"\\nScores: {prediction.scores.cpu().numpy()}\")\n",
    "        print(f\"\\nFeatures (first detection, first 10 dims): {prediction.features[0, :10].cpu().numpy()}\")\n",
    "        print(f\"Feature dtype: {prediction.features.dtype}\")\n",
    "        print(f\"Feature device: {prediction.features.device}\")\n",
    "        \n",
    "        # Verify feature dimensions are correct (256-d)\n",
    "        assert prediction.features.shape[1] == 256, f\"Expected 256-d features, got {prediction.features.shape[1]}\"\n",
    "        print(\"\\n✅ Feature dimensions are correct (256-d)\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ No detections found for this image/prompt combination\")\n",
    "else:\n",
    "    print(\"❌ No test images available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684dc75",
   "metadata": {},
   "source": [
    "### Test All Classes on One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all class prompts on first image\n",
    "if test_image_files:\n",
    "    test_img = test_image_files[0]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing all classes on: {test_img.name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for class_id, prompt in CLASS_PROMPTS.items():\n",
    "        print(f\"\\nClass {class_id}: '{prompt}'\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        prediction = model.predict_with_text(test_img, prompt)\n",
    "        \n",
    "        num_det = prediction.boxes.shape[0]\n",
    "        print(f\"  Detections: {num_det}\")\n",
    "        \n",
    "        if num_det > 0:\n",
    "            print(f\"  Scores: {prediction.scores.cpu().numpy()}\")\n",
    "            print(f\"  Features shape: {prediction.features.shape}\")\n",
    "            print(f\"  Feature mean: {prediction.features.mean().item():.4f}\")\n",
    "            print(f\"  Feature std: {prediction.features.std().item():.4f}\")\n",
    "        else:\n",
    "            print(f\"  Features shape: {prediction.features.shape} (empty)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ All class predictions completed successfully!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44eca1",
   "metadata": {},
   "source": [
    "## 5. Test Complete Pipeline on Multiple Images\n",
    "\n",
    "Simulate the full `run_sam3_on_split` workflow on a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9658070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.yolo_export import sam3_boxes_to_yolo, YoloBox\n",
    "\n",
    "# Test on up to 3 images\n",
    "test_limit = min(3, len(test_image_files))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Testing complete pipeline on {test_limit} images\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for idx, img_path in enumerate(test_image_files[:test_limit], 1):\n",
    "    print(f\"\\n[{idx}/{test_limit}] Processing {img_path.name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "    \n",
    "    all_boxes = []\n",
    "    all_features = []\n",
    "    \n",
    "    # Loop over all classes\n",
    "    for class_id, prompt in CLASS_PROMPTS.items():\n",
    "        prediction = model.predict_with_text(img_path, prompt)\n",
    "        \n",
    "        # Convert to YOLO format\n",
    "        yolo_boxes = sam3_boxes_to_yolo(\n",
    "            prediction=prediction,\n",
    "            class_id=class_id,\n",
    "            image_width=width,\n",
    "            image_height=height,\n",
    "            score_threshold=0.26,\n",
    "        )\n",
    "        \n",
    "        all_boxes.extend(yolo_boxes)\n",
    "        \n",
    "        print(f\"  Class {class_id}: {len(yolo_boxes)} boxes\")\n",
    "    \n",
    "    print(f\"\\n  Total boxes: {len(all_boxes)}\")\n",
    "    \n",
    "    # Check that all boxes have features\n",
    "    boxes_with_features = sum(1 for box in all_boxes if box.features is not None)\n",
    "    boxes_without_features = len(all_boxes) - boxes_with_features\n",
    "    \n",
    "    print(f\"  Boxes with features: {boxes_with_features}\")\n",
    "    print(f\"  Boxes without features: {boxes_without_features}\")\n",
    "    \n",
    "    if boxes_without_features > 0:\n",
    "        print(\"\\n  ❌ ERROR: Some boxes are missing features!\")\n",
    "    else:\n",
    "        print(\"\\n  ✅ All boxes have features\")\n",
    "        \n",
    "        # Build 257-d feature vectors (256-d features + score)\n",
    "        for box in all_boxes:\n",
    "            score_val = box.score if box.score is not None else 0.0\n",
    "            feat_with_score = np.concatenate([box.features, [score_val]]).astype(np.float32)\n",
    "            all_features.append(feat_with_score)\n",
    "        \n",
    "        if all_features:\n",
    "            features_arr = np.array(all_features, dtype=np.float16)\n",
    "            print(f\"  Final features array shape: {features_arr.shape}\")\n",
    "            print(f\"  Expected shape: ({len(all_boxes)}, 257)\")\n",
    "            \n",
    "            assert features_arr.shape == (len(all_boxes), 257), \"Feature shape mismatch!\"\n",
    "            print(\"  ✅ Feature array shape is correct!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ Pipeline test completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa6fbf",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Detection\n",
    "\n",
    "Show detections with bounding boxes on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de08b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "if test_image_files:\n",
    "    # Use first image\n",
    "    test_img = test_image_files[0]\n",
    "    image = Image.open(test_img).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Get predictions for first class only (to keep visualization clean)\n",
    "    prompt = CLASS_PROMPTS[0]\n",
    "    prediction = model.predict_with_text(test_img, prompt)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f\"SAM3 Detections: {test_img.name}\\nPrompt: '{prompt}'\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    if prediction.boxes.shape[0] > 0:\n",
    "        boxes_np = prediction.boxes.cpu().numpy()\n",
    "        scores_np = prediction.scores.cpu().numpy()\n",
    "        \n",
    "        for i, (box, score) in enumerate(zip(boxes_np, scores_np)):\n",
    "            x1, y1, x2, y2 = box\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), w, h,\n",
    "                linewidth=2,\n",
    "                edgecolor='red',\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add score label\n",
    "            ax.text(\n",
    "                x1, y1 - 5,\n",
    "                f'{score:.2f}',\n",
    "                color='white',\n",
    "                fontsize=10,\n",
    "                bbox=dict(facecolor='red', alpha=0.7, edgecolor='none', pad=2)\n",
    "            )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDetections: {prediction.boxes.shape[0]}\")\n",
    "    print(f\"Features extracted: {prediction.features.shape[0]} x {prediction.features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29b363",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "If all cells above ran successfully, the SAM3 feature extraction is working correctly!\n",
    "\n",
    "**Expected results:**\n",
    "- ✅ SAM3 model loads without errors\n",
    "- ✅ Predictions return boxes, scores, masks, and **features**\n",
    "- ✅ Features have shape (N, 256) where N = number of detections\n",
    "- ✅ All boxes have associated features (no missing values)\n",
    "- ✅ Final feature array has shape (N, 257) after concatenating score\n",
    "\n",
    "**Next steps:**\n",
    "1. Run `run_sam3_on_split.py` on the train split to generate features for all images\n",
    "2. Run `build_linear_probe_dataset.py` to create the training dataset\n",
    "3. Run `train_linear_probe.py` to train the classifier\n",
    "4. Run `apply_linear_probe_to_split.py` to apply it on the test split\n",
    "5. Evaluate results with `eval_sam3_linear_probe_on_split.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable debug mode\n",
    "os.environ[\"SAM3_DEBUG\"] = \"0\"\n",
    "print(\"✅ Test notebook completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
