{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa932db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup (Colab auto-installs, local adds to path)\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    %cd /content\n",
    "    !git clone https://github.com/AntoFratta/DVARF.git\n",
    "    %cd /content/DVARF\n",
    "    !grep -v \"triton-windows\" requirements.txt > requirements_colab.txt\n",
    "    !pip install -q -r requirements_colab.txt\n",
    "    print(\"✅ Setup complete!\")\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    print(f\"✅ Local: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad82dca",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90970926",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# Clone the DVARF repository\n",
    "!git clone https://github.com/AntoFratta/DVARF.git\n",
    "\n",
    "%cd /content/DVARF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c5cb6",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Colab-compatible requirements file by removing Windows-specific packages\n",
    "!grep -v \"triton-windows\" requirements.txt > requirements_colab.txt\n",
    "\n",
    "# Install all dependencies\n",
    "!pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c1c56",
   "metadata": {},
   "source": [
    "## 3. Install SAM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49401743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# Clone the official SAM 3 repository from Meta\n",
    "!git clone https://github.com/facebookresearch/sam3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/sam3\n",
    "\n",
    "# Install SAM 3 in editable mode\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3053c",
   "metadata": {},
   "source": [
    "## 4. Hugging Face Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Login to Hugging Face (widget will prompt for your token)\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b7cda",
   "metadata": {},
   "source": [
    "## 5. Test Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc078963",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/DVARF\n",
    "\n",
    "import sys\n",
    "if \"/content/DVARF\" not in sys.path:\n",
    "    sys.path.insert(0, \"/content/DVARF\")\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from src.sam3_wrapper import Sam3ImageModel\n",
    "from src.prompts import CLASS_PROMPTS\n",
    "from src.yolo_export import sam3_boxes_to_yolo\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"\\nClasses: {CLASS_PROMPTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3796e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM3 model (enable debug to see internal structure)\n",
    "os.environ[\"SAM3_DEBUG\"] = \"1\"\n",
    "\n",
    "print(\"Loading SAM3...\")\n",
    "# Use HuggingFace checkpoint explicitly\n",
    "model = Sam3ImageModel(checkpoint_path=\"facebook/sam3-image-large\")\n",
    "print(\"✅ Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test images\n",
    "project_root = Path(\"/content/DVARF\")\n",
    "test_images_dir = project_root / \"data\" / \"raw\" / \"images\" / \"test\"\n",
    "test_image_files = sorted(test_images_dir.glob(\"*.jpg\"))[:3]\n",
    "\n",
    "print(f\"Test images ({len(test_image_files)}):\")\n",
    "for img in test_image_files:\n",
    "    print(f\"  {img.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168982c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single image + single prompt\n",
    "test_img = test_image_files[0]\n",
    "test_prompt = CLASS_PROMPTS[0]\n",
    "\n",
    "print(f\"Image: {test_img.name}\")\n",
    "print(f\"Prompt: '{test_prompt}'\\n\")\n",
    "\n",
    "prediction = model.predict_with_text(test_img, test_prompt)\n",
    "\n",
    "print(f\"\\n✅ Boxes: {prediction.boxes.shape}\")\n",
    "print(f\"✅ Scores: {prediction.scores.shape}\")\n",
    "print(f\"✅ Masks: {prediction.masks.shape}\")\n",
    "print(f\"✅ Features: {prediction.features.shape}\")\n",
    "\n",
    "if prediction.boxes.shape[0] > 0:\n",
    "    print(f\"\\nScores: {prediction.scores.cpu().numpy()}\")\n",
    "    print(f\"Features sample: {prediction.features[0, :10].cpu().numpy()}\")\n",
    "    assert prediction.features.shape[1] == 256, \"Expected 256-d features\"\n",
    "    print(\"\\n✅ Feature dimensions correct (256-d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all classes on one image\n",
    "test_img = test_image_files[0]\n",
    "\n",
    "print(f\"Testing all classes on: {test_img.name}\\n\")\n",
    "\n",
    "for class_id, prompt in CLASS_PROMPTS.items():\n",
    "    prediction = model.predict_with_text(test_img, prompt)\n",
    "    num_det = prediction.boxes.shape[0]\n",
    "    \n",
    "    print(f\"Class {class_id} ('{prompt}'): {num_det} detections\")\n",
    "    if num_det > 0:\n",
    "        print(f\"  Scores: {prediction.scores.cpu().numpy()}\")\n",
    "        print(f\"  Features: {prediction.features.shape}\")\n",
    "\n",
    "print(\"\\n✅ All classes tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete pipeline (simulate run_sam3_on_split)\n",
    "print(f\"Testing pipeline on {len(test_image_files)} images\\n\")\n",
    "\n",
    "for idx, img_path in enumerate(test_image_files, 1):\n",
    "    print(f\"[{idx}/{len(test_image_files)}] {img_path.name}\")\n",
    "    \n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "    \n",
    "    all_boxes = []\n",
    "    \n",
    "    # Query all classes\n",
    "    for class_id, prompt in CLASS_PROMPTS.items():\n",
    "        prediction = model.predict_with_text(img_path, prompt)\n",
    "        \n",
    "        yolo_boxes = sam3_boxes_to_yolo(\n",
    "            prediction=prediction,\n",
    "            class_id=class_id,\n",
    "            image_width=width,\n",
    "            image_height=height,\n",
    "            score_threshold=0.26,\n",
    "        )\n",
    "        \n",
    "        all_boxes.extend(yolo_boxes)\n",
    "        print(f\"  Class {class_id}: {len(yolo_boxes)} boxes\")\n",
    "    \n",
    "    # Check all boxes have features\n",
    "    boxes_with_features = sum(1 for box in all_boxes if box.features is not None)\n",
    "    boxes_without = len(all_boxes) - boxes_with_features\n",
    "    \n",
    "    print(f\"  Total: {len(all_boxes)} boxes, {boxes_with_features} with features\")\n",
    "    \n",
    "    if boxes_without > 0:\n",
    "        print(f\"  ❌ ERROR: {boxes_without} boxes missing features!\")\n",
    "    else:\n",
    "        # Build 257-d features (256 + score)\n",
    "        all_features = []\n",
    "        for box in all_boxes:\n",
    "            score_val = box.score if box.score is not None else 0.0\n",
    "            feat_257 = np.concatenate([box.features, [score_val]]).astype(np.float32)\n",
    "            all_features.append(feat_257)\n",
    "        \n",
    "        if all_features:\n",
    "            features_arr = np.array(all_features, dtype=np.float16)\n",
    "            print(f\"  ✅ Features array: {features_arr.shape} (expected: {len(all_boxes)}, 257)\")\n",
    "            assert features_arr.shape == (len(all_boxes), 257)\n",
    "\n",
    "print(\"\\n✅ Pipeline test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detections\n",
    "test_img = test_image_files[0]\n",
    "image = Image.open(test_img).convert(\"RGB\")\n",
    "prompt = CLASS_PROMPTS[0]\n",
    "prediction = model.predict_with_text(test_img, prompt)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.imshow(image)\n",
    "ax.set_title(f\"{test_img.name} - '{prompt}'\")\n",
    "ax.axis('off')\n",
    "\n",
    "if prediction.boxes.shape[0] > 0:\n",
    "    boxes_np = prediction.boxes.cpu().numpy()\n",
    "    scores_np = prediction.scores.cpu().numpy()\n",
    "    \n",
    "    for box, score in zip(boxes_np, scores_np):\n",
    "        x1, y1, x2, y2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), w, h,\n",
    "            linewidth=2, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        ax.text(\n",
    "            x1, y1 - 5, f'{score:.2f}',\n",
    "            color='white', fontsize=10,\n",
    "            bbox=dict(facecolor='red', alpha=0.7, edgecolor='none', pad=2)\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detections: {prediction.boxes.shape[0]}\")\n",
    "print(f\"Features: {prediction.features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "os.environ[\"SAM3_DEBUG\"] = \"0\"\n",
    "print(\"✅ Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7114f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "if IN_COLAB:\n",
    "    project_root = Path(\"/content/DVARF\")\n",
    "else:\n",
    "    project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.sam3_wrapper import Sam3ImageModel\n",
    "from src.prompts import CLASS_PROMPTS\n",
    "from src.config import get_images_dir\n",
    "from src.yolo_export import sam3_boxes_to_yolo, YoloBox\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"\\nClasses: {CLASS_PROMPTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Login to Hugging Face to download SAM3 model\n",
    "from huggingface_hub import login\n",
    "\n",
    "print(\"Please login to Hugging Face to download SAM3:\")\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7315272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load SAM3 model (enable debug to see internal structure)\n",
    "os.environ[\"SAM3_DEBUG\"] = \"1\"\n",
    "\n",
    "print(\"Loading SAM3...\")\n",
    "model = Sam3ImageModel()\n",
    "print(\"✅ Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Get test images\n",
    "test_images_dir = project_root / \"data\" / \"raw\" / \"images\" / \"test\"\n",
    "test_image_files = sorted(test_images_dir.glob(\"*.jpg\"))[:3]\n",
    "\n",
    "print(f\"Test images ({len(test_image_files)}):\")\n",
    "for img in test_image_files:\n",
    "    print(f\"  {img.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6701ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test single image + single prompt\n",
    "test_img = test_image_files[0]\n",
    "test_prompt = CLASS_PROMPTS[0]\n",
    "\n",
    "print(f\"Image: {test_img.name}\")\n",
    "print(f\"Prompt: '{test_prompt}'\\n\")\n",
    "\n",
    "prediction = model.predict_with_text(test_img, test_prompt)\n",
    "\n",
    "print(f\"\\n✅ Boxes: {prediction.boxes.shape}\")\n",
    "print(f\"✅ Scores: {prediction.scores.shape}\")\n",
    "print(f\"✅ Masks: {prediction.masks.shape}\")\n",
    "print(f\"✅ Features: {prediction.features.shape}\")\n",
    "\n",
    "if prediction.boxes.shape[0] > 0:\n",
    "    print(f\"\\nScores: {prediction.scores.cpu().numpy()}\")\n",
    "    print(f\"Features sample: {prediction.features[0, :10].cpu().numpy()}\")\n",
    "    assert prediction.features.shape[1] == 256, \"Expected 256-d features\"\n",
    "    print(\"\\n✅ Feature dimensions correct (256-d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4844e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test all classes on one image\n",
    "test_img = test_image_files[0]\n",
    "\n",
    "print(f\"Testing all classes on: {test_img.name}\\n\")\n",
    "\n",
    "for class_id, prompt in CLASS_PROMPTS.items():\n",
    "    prediction = model.predict_with_text(test_img, prompt)\n",
    "    num_det = prediction.boxes.shape[0]\n",
    "    \n",
    "    print(f\"Class {class_id} ('{prompt}'): {num_det} detections\")\n",
    "    if num_det > 0:\n",
    "        print(f\"  Scores: {prediction.scores.cpu().numpy()}\")\n",
    "        print(f\"  Features: {prediction.features.shape}\")\n",
    "\n",
    "print(\"\\n✅ All classes tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test complete pipeline (simulate run_sam3_on_split)\n",
    "print(f\"Testing pipeline on {len(test_image_files)} images\\n\")\n",
    "\n",
    "for idx, img_path in enumerate(test_image_files, 1):\n",
    "    print(f\"[{idx}/{len(test_image_files)}] {img_path.name}\")\n",
    "    \n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "    \n",
    "    all_boxes = []\n",
    "    \n",
    "    # Query all classes\n",
    "    for class_id, prompt in CLASS_PROMPTS.items():\n",
    "        prediction = model.predict_with_text(img_path, prompt)\n",
    "        \n",
    "        yolo_boxes = sam3_boxes_to_yolo(\n",
    "            prediction=prediction,\n",
    "            class_id=class_id,\n",
    "            image_width=width,\n",
    "            image_height=height,\n",
    "            score_threshold=0.26,\n",
    "        )\n",
    "        \n",
    "        all_boxes.extend(yolo_boxes)\n",
    "        print(f\"  Class {class_id}: {len(yolo_boxes)} boxes\")\n",
    "    \n",
    "    # Check all boxes have features\n",
    "    boxes_with_features = sum(1 for box in all_boxes if box.features is not None)\n",
    "    boxes_without = len(all_boxes) - boxes_with_features\n",
    "    \n",
    "    print(f\"  Total: {len(all_boxes)} boxes, {boxes_with_features} with features\")\n",
    "    \n",
    "    if boxes_without > 0:\n",
    "        print(f\"  ❌ ERROR: {boxes_without} boxes missing features!\")\n",
    "    else:\n",
    "        # Build 257-d features (256 + score)\n",
    "        all_features = []\n",
    "        for box in all_boxes:\n",
    "            score_val = box.score if box.score is not None else 0.0\n",
    "            feat_257 = np.concatenate([box.features, [score_val]]).astype(np.float32)\n",
    "            all_features.append(feat_257)\n",
    "        \n",
    "        if all_features:\n",
    "            features_arr = np.array(all_features, dtype=np.float16)\n",
    "            print(f\"  ✅ Features array: {features_arr.shape} (expected: {len(all_boxes)}, 257)\")\n",
    "            assert features_arr.shape == (len(all_boxes), 257)\n",
    "\n",
    "print(\"\\n✅ Pipeline test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fce56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualize detections\n",
    "test_img = test_image_files[0]\n",
    "image = Image.open(test_img).convert(\"RGB\")\n",
    "prompt = CLASS_PROMPTS[0]\n",
    "prediction = model.predict_with_text(test_img, prompt)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.imshow(image)\n",
    "ax.set_title(f\"{test_img.name} - '{prompt}'\")\n",
    "ax.axis('off')\n",
    "\n",
    "if prediction.boxes.shape[0] > 0:\n",
    "    boxes_np = prediction.boxes.cpu().numpy()\n",
    "    scores_np = prediction.scores.cpu().numpy()\n",
    "    \n",
    "    for box, score in zip(boxes_np, scores_np):\n",
    "        x1, y1, x2, y2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), w, h,\n",
    "            linewidth=2, edgecolor='red', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        ax.text(\n",
    "            x1, y1 - 5, f'{score:.2f}',\n",
    "            color='white', fontsize=10,\n",
    "            bbox=dict(facecolor='red', alpha=0.7, edgecolor='none', pad=2)\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detections: {prediction.boxes.shape[0]}\")\n",
    "print(f\"Features: {prediction.features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Cleanup\n",
    "os.environ[\"SAM3_DEBUG\"] = \"0\"\n",
    "print(\"✅ Test complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
